{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ff165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Merge CSV Files from q1‚Äìq30\n",
    "# This notebook walks through folders q1 to q30, loads all CSV files,\n",
    "# and merges them into a single CSV file.\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b7dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q\n",
      "Output directory: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/merged_output\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Set Base Directory\n",
    "# Update BASE_DIR to the folder that contains q1, q2, ..., q30.\n",
    "# Example (Colab + Google Drive):\n",
    "# BASE_DIR = Path(\"/content/drive/MyDrive/elexy-algorithm\")\n",
    "# Example (local):\n",
    "# BASE_DIR = Path(r\"C:\\Users\\Nitin\\Desktop\\your_folder\")\n",
    "\n",
    "# %%\n",
    "BASE_DIR = Path(\"/home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q\")  # üîÅ change this if needed\n",
    "\n",
    "# Where to save the merged CSV\n",
    "OUTPUT_DIR = BASE_DIR / \"merged_output\"\n",
    "OUTPUT_FILENAME = \"merged_q1_q30.csv\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Base directory:\", BASE_DIR)\n",
    "print(\"Output directory:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243803f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files found: 30\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q1/Summary_csl100_q1.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q2/Summary_csl100_q2.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q3/Summary_csl100_q3.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q4/Summary_csl100_q4.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q5/Summary_csl100_q5.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q6/Summary_csl100_q6.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q7/Summary_csl100_q7.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q8/Summary_csl100_q8.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q9/Summary_csl100_q9.csv\n",
      " - /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q10/Summary_csl100_q10.csv\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Collect CSV Files from q1 to q30\n",
    "# We will:\n",
    "# - Loop over folder names: q1, q2, ..., q30\n",
    "# - For each existing folder, search **recursively** for `.csv` files\n",
    "\n",
    "# %%\n",
    "csv_files = []\n",
    "\n",
    "for i in range(1, 31):\n",
    "    folder_name = f\"q{i}\"\n",
    "    folder_path = BASE_DIR / folder_name\n",
    "    \n",
    "    if not folder_path.is_dir():\n",
    "        print(f\"[WARN] Folder not found, skipping: {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    # rglob(\"*.csv\") finds CSVs inside subfolders too\n",
    "    for csv_path in folder_path.rglob(\"*.csv\"):\n",
    "        csv_files.append(csv_path)\n",
    "\n",
    "print(f\"Total CSV files found: {len(csv_files)}\")\n",
    "for p in csv_files[:10]:\n",
    "    print(\" -\", p)\n",
    "if len(csv_files) > 10:\n",
    "    print(\"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc477fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q1/Summary_csl100_q1.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q2/Summary_csl100_q2.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q3/Summary_csl100_q3.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q4/Summary_csl100_q4.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q5/Summary_csl100_q5.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q6/Summary_csl100_q6.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q7/Summary_csl100_q7.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q8/Summary_csl100_q8.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q9/Summary_csl100_q9.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q10/Summary_csl100_q10.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q11/Summary_csl100_q11.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q12/Summary_csl100_q12.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q13/Summary_csl100_q13.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q14/Summary_csl100_q14.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q15/Summary_csl100_q15.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q16/Summary_csl100_q16.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q17/Summary_csl100_q17.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q18/Summary_csl100_q18.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q19/Summary_csl100_q19.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q20/Summary_csl100_q20.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q21/Summary_csl100_q21.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q22/Summary_csl100_q22.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q23/Summary_csl100_q23.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q24/Summary_csl100_q24.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q25/Summary_csl100_q25.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q26/Summary_csl100_q26.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q27/Summary_csl100_q27.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q28/Summary_csl100_q28.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q29/Summary_csl100_q29.csv\n",
      "[OK] Loaded: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/q30/Summary_csl100_q30.csv\n",
      "‚úÖ Merged DataFrame shape: (8435, 8)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Load and Merge All CSVs\n",
    "# - Use `pandas.read_csv` with robust settings.\n",
    "# - Add `source_folder` and `source_file` columns for traceability.\n",
    "# - Concatenate all into one DataFrame.\n",
    "\n",
    "# %%\n",
    "all_dfs = []\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            engine=\"python\",         # safer for weird delimiters\n",
    "            on_bad_lines=\"skip\",     # skip broken lines instead of crashing\n",
    "        )\n",
    "        \n",
    "        # Add metadata columns to know origin of each row\n",
    "        df[\"source_folder\"] = csv_path.parent.name\n",
    "        df[\"source_file\"] = csv_path.name\n",
    "        \n",
    "        all_dfs.append(df)\n",
    "        print(f\"[OK] Loaded: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not read {csv_path}: {e}\")\n",
    "\n",
    "if not all_dfs:\n",
    "    print(\"‚ùå No CSVs loaded. Please check paths / folders.\")\n",
    "else:\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"‚úÖ Merged DataFrame shape:\", merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48787654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>tests_passed</th>\n",
       "      <th>tests_total</th>\n",
       "      <th>score_percentage</th>\n",
       "      <th>semantic_summary</th>\n",
       "      <th>code_snippet</th>\n",
       "      <th>source_folder</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B25DS027_q1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;output&gt; The issue lies in how you're modifyin...</td>\n",
       "      <td>def fizzbuzz(n):\\n    lst = [i for i in range(...</td>\n",
       "      <td>q1</td>\n",
       "      <td>Summary_csl100_q1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B25DS021_q1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;output&gt;Consider adding a check for the input ...</td>\n",
       "      <td>def fizzbuzz(limit):\\n    output = []\\n    for...</td>\n",
       "      <td>q1</td>\n",
       "      <td>Summary_csl100_q1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B25DS024_Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;output&gt;Consider using a list comprehension to...</td>\n",
       "      <td>def fizzbuzz(n):\\n    result = []\\n    for i i...</td>\n",
       "      <td>q1</td>\n",
       "      <td>Summary_csl100_q1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B25CS046_q1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>&lt;output&gt;Consider using a list comprehension to...</td>\n",
       "      <td>def fizzbuzz(n):\\n    l=[]\\n    for _ in range...</td>\n",
       "      <td>q1</td>\n",
       "      <td>Summary_csl100_q1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B25DS039_Q1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;output&gt;Consider using a conditional expressio...</td>\n",
       "      <td>def fizzbuzz(n):\\n    L=[]\\n    for i in range...</td>\n",
       "      <td>q1</td>\n",
       "      <td>Summary_csl100_q1.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_id  tests_passed  tests_total  score_percentage  \\\n",
       "0  B25DS027_q1             6            6             100.0   \n",
       "1  B25DS021_q1             6            6             100.0   \n",
       "2  B25DS024_Q1             0            6               0.0   \n",
       "3  B25CS046_q1             3            6              50.0   \n",
       "4  B25DS039_Q1             6            6             100.0   \n",
       "\n",
       "                                    semantic_summary  \\\n",
       "0  <output> The issue lies in how you're modifyin...   \n",
       "1  <output>Consider adding a check for the input ...   \n",
       "2  <output>Consider using a list comprehension to...   \n",
       "3  <output>Consider using a list comprehension to...   \n",
       "4  <output>Consider using a conditional expressio...   \n",
       "\n",
       "                                        code_snippet source_folder  \\\n",
       "0  def fizzbuzz(n):\\n    lst = [i for i in range(...            q1   \n",
       "1  def fizzbuzz(limit):\\n    output = []\\n    for...            q1   \n",
       "2  def fizzbuzz(n):\\n    result = []\\n    for i i...            q1   \n",
       "3  def fizzbuzz(n):\\n    l=[]\\n    for _ in range...            q1   \n",
       "4  def fizzbuzz(n):\\n    L=[]\\n    for i in range...            q1   \n",
       "\n",
       "             source_file  \n",
       "0  Summary_csl100_q1.csv  \n",
       "1  Summary_csl100_q1.csv  \n",
       "2  Summary_csl100_q1.csv  \n",
       "3  Summary_csl100_q1.csv  \n",
       "4  Summary_csl100_q1.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in merged_df:\n",
      "['student_id', 'tests_passed', 'tests_total', 'score_percentage', 'semantic_summary', 'code_snippet', 'source_folder', 'source_file']\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Preview Merged Data\n",
    "\n",
    "# %%\n",
    "if 'merged_df' in locals():\n",
    "    display(merged_df.head())\n",
    "    print(\"\\nColumns in merged_df:\")\n",
    "    print(list(merged_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f8054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged CSV saved at:\n",
      "/home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/merged_output/merged_q1_q30.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Save Merged CSV to Disk\n",
    "\n",
    "# %%\n",
    "if 'merged_df' in locals():\n",
    "    output_path = OUTPUT_DIR / OUTPUT_FILENAME\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Merged CSV saved at:\\n{output_path}\")\n",
    "else:\n",
    "    print(\"‚ùå merged_df does not exist, nothing to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85aeb3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 8435\n",
      "After removing score_percentage == 100.0: 5442\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Create 16 Excel sheets with random samples\n",
    "# - Ignore rows where score_percentage == 100.0\n",
    "# - Randomly assign 50 rows per sheet\n",
    "# - No repetition across sheets\n",
    "# - Add blank \"remark\" column in each sheet\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# If you don't already have merged_df loaded, you can reload it:\n",
    "# merged_df = pd.read_csv(OUTPUT_DIR / \"merged_q1_q30.csv\")\n",
    "\n",
    "# 1. Filter out rows with score_percentage == 100.0\n",
    "if \"score_percentage\" not in merged_df.columns:\n",
    "    raise KeyError(\"'score_percentage' column not found in merged_df!\")\n",
    "\n",
    "filtered_df = merged_df[merged_df[\"score_percentage\"] != 100.0].copy()\n",
    "\n",
    "print(\"Original rows:\", len(merged_df))\n",
    "print(\"After removing score_percentage == 100.0:\", len(filtered_df))\n",
    "\n",
    "# 2. Shuffle the filtered rows\n",
    "filtered_df = filtered_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08daa9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows available for sampling: 5442\n",
      "Rows that will be used: 800\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Split into 16 groups of 50 rows (no repetition)\n",
    "# If there are fewer than 800 usable rows, some sheets will have fewer rows\n",
    "# (or we stop earlier).\n",
    "\n",
    "# %%\n",
    "rows_per_sheet = 50\n",
    "num_sheets = 16\n",
    "total_needed = rows_per_sheet * num_sheets\n",
    "\n",
    "available_rows = len(filtered_df)\n",
    "rows_to_use = min(total_needed, available_rows)\n",
    "\n",
    "print(f\"Rows available for sampling: {available_rows}\")\n",
    "print(f\"Rows that will be used: {rows_to_use}\")\n",
    "\n",
    "selected_df = filtered_df.iloc[:rows_to_use].reset_index(drop=True)\n",
    "\n",
    "# Sanity: no repetition because we sliced unique rows\n",
    "assert len(selected_df) == rows_to_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f2b59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/merged_output/random_16_sheets_no100.xlsx')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Create Excel file with 16 sheets\n",
    "# - Sheet names: Sheet1, Sheet2, ..., Sheet16\n",
    "# - Each sheet gets up to 50 rows\n",
    "# - Adds a blank 'remark' column\n",
    "\n",
    "# %%\n",
    "OUTPUT_EXCEL = OUTPUT_DIR / \"random_16_sheets_no100.xlsx\"\n",
    "OUTPUT_EXCEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6c0655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote 50 rows to Sheet1\n",
      "[OK] Wrote 50 rows to Sheet2\n",
      "[OK] Wrote 50 rows to Sheet3\n",
      "[OK] Wrote 50 rows to Sheet4\n",
      "[OK] Wrote 50 rows to Sheet5\n",
      "[OK] Wrote 50 rows to Sheet6\n",
      "[OK] Wrote 50 rows to Sheet7\n",
      "[OK] Wrote 50 rows to Sheet8\n",
      "[OK] Wrote 50 rows to Sheet9\n",
      "[OK] Wrote 50 rows to Sheet10\n",
      "[OK] Wrote 50 rows to Sheet11\n",
      "[OK] Wrote 50 rows to Sheet12\n",
      "[OK] Wrote 50 rows to Sheet13\n",
      "[OK] Wrote 50 rows to Sheet14\n",
      "[OK] Wrote 50 rows to Sheet15\n",
      "[OK] Wrote 50 rows to Sheet16\n",
      "\n",
      "‚úÖ Excel file created at: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/merged_output/random_16_sheets_no100.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "with pd.ExcelWriter(OUTPUT_EXCEL, engine=\"xlsxwriter\") as writer:\n",
    "    for i in range(num_sheets):\n",
    "        start = i * rows_per_sheet\n",
    "        end = start + rows_per_sheet\n",
    "        \n",
    "        sheet_df = selected_df.iloc[start:end].copy()\n",
    "        \n",
    "        # If no rows left for this sheet, stop creating more sheets\n",
    "        if sheet_df.empty:\n",
    "            print(f\"[INFO] No more rows left for Sheet{i+1}, stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Add blank 'remark' column\n",
    "        sheet_df[\"remark\"] = \"\"\n",
    "        \n",
    "        sheet_name = f\"Sheet{i+1}\"\n",
    "        sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"[OK] Wrote {len(sheet_df)} rows to {sheet_name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Excel file created at: {OUTPUT_EXCEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77281118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Created sheet: Sheet1 with 50 rows\n",
      "[OK] Created sheet: Sheet2 with 50 rows\n",
      "[OK] Created sheet: Sheet3 with 50 rows\n",
      "[OK] Created sheet: Sheet4 with 50 rows\n",
      "[OK] Created sheet: Sheet5 with 50 rows\n",
      "[OK] Created sheet: Sheet6 with 50 rows\n",
      "[OK] Created sheet: Sheet7 with 50 rows\n",
      "[OK] Created sheet: Sheet8 with 50 rows\n",
      "[OK] Created sheet: Sheet9 with 50 rows\n",
      "[OK] Created sheet: Sheet10 with 50 rows\n",
      "[OK] Created sheet: Sheet11 with 50 rows\n",
      "[OK] Created sheet: Sheet12 with 50 rows\n",
      "[OK] Created sheet: Sheet13 with 50 rows\n",
      "[OK] Created sheet: Sheet14 with 50 rows\n",
      "[OK] Created sheet: Sheet15 with 50 rows\n",
      "[OK] Created sheet: Sheet16 with 50 rows\n",
      "\n",
      "‚úÖ Excel with evaluation columns created at: /home/vikrant/Project/CSL100/AutoGrader_CSL100/reports/CSL100/Prac_30Q/merged_output/random_16_sheets_eval.xlsx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_EXCEL = OUTPUT_DIR / \"random_16_sheets_eval.xlsx\"\n",
    "\n",
    "rows_per_sheet = 50\n",
    "num_sheets = 16\n",
    "\n",
    "# Evaluation columns for journal human evaluation\n",
    "eval_cols = [\"correctness\", \"usefulness\", \"final_verdict\"]\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_EXCEL, engine=\"xlsxwriter\") as writer:\n",
    "    for i in range(num_sheets):\n",
    "        start = i * rows_per_sheet\n",
    "        end = start + rows_per_sheet\n",
    "        \n",
    "        sheet_df = selected_df.iloc[start:end].copy()\n",
    "        \n",
    "        if sheet_df.empty:\n",
    "            print(f\"[INFO] No more rows left for Sheet{i+1}, stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Keep previous remark column (optional)\n",
    "        sheet_df[\"remark\"] = \"\"\n",
    "        \n",
    "        # Add the 3 human-evaluation columns\n",
    "        for col in eval_cols:\n",
    "            sheet_df[col] = \"\"  # TA will fill 0/1/2\n",
    "        \n",
    "        sheet_name = f\"Sheet{i+1}\"\n",
    "        sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"[OK] Created sheet: {sheet_name} with {len(sheet_df)} rows\")\n",
    "\n",
    "print(f\"\\n‚úÖ Excel with evaluation columns created at: {OUTPUT_EXCEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m250.9/250.9 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc05ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
